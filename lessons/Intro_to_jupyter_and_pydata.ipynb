{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to Jupyter notebooks and the PyData stack\n",
    "\n",
    "A Jupyter notebook (formally iPython) is an interactive environment for Python, and it's probably the best way of using Python for data manipulation.  You may ask: \"I can just run python interactively from the terminal, why do I need jupyter?\"  Well, that's a fair question, and the answer will hopefully become clear as we work through this notebook.\n",
    "\n",
    "Jupyter notebooks are broken down into **cells**.  We're in the topmost cell of this notebook at the moment.  Cells come in three flavors:\n",
    "\n",
    "* **Markdown cells** allows you to edit the text in Markdown.  These cells are used for exposition, discussion, and general formatting.  Think of them as extended comments that can be formatted beautifully, and can contain [links](http://www.jupyter.org), bulleted lists, etc.  Anything that Markdown can!  It even allows for LaTeX:\n",
    "$$\\int_{1}^{\\sqrt[3]{3}} z^2 dz \\cdot cos\\left(\\frac{3\\cdot\\pi}{9}\\right) = \\ln \\left(\\sqrt[3]{e}\\right)$$\n",
    "* **Code cells** contain code (for us, Python code).  These cells can contain code as short as one line, or as long as you'd like!  (Actually, I have no idea what the maximum length is.  I've had cells well over 100 lines long though).  They have some basic text editor support, so they'll help you with indentation, tab completion, etc., but they won't be able to do some of the magic that true editors like Atom or Sublime can handle.  They're also interactive in the same way that the Python interpretter in interactive mode is.  Type `15*4 %3` and it returns the answer, no need to `print` out everything.\n",
    "\n",
    "There's one more, but it's not used as often:\n",
    "\n",
    "* **Raw cells** are used when you want to hack the notebook to make it fancier.  We won't be using them tons, but it's good to know they exist.\n",
    "\n",
    "How about a little demonstation?  Run the code cell below with `shift + enter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_prime(n):\n",
    "    \"\"\" Determine whether n is prime.\"\"\"\n",
    "    k = 2\n",
    "    while k*k <= n:\n",
    "        if n % k == 0:\n",
    "            return False\n",
    "        k += 1\n",
    "    return True\n",
    "\n",
    "x = [x for x in range(2,401) if is_prime(x)]\n",
    "\n",
    "print(*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As proof that the function is in memory, let's query the function\n",
    "print(is_prime, type(is_prime), is_prime(57), sep=\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editting a notebook: Command mode and Edit mode\n",
    "\n",
    "While working with a notebook, you are always in one of two modes.\n",
    "\n",
    "1. In **Edit mode** you can edit the content of a cell.  You're in edit mode in a cell when the left border of the cell is green.  It acts like a text file inside a text editor, and has some helpful syntax highlighting.  If you're editing a Markdown cell, it will look significantly different.  If you're editing a code cell, it will look mostly the same.  To *run* the cell, you have a few options:\n",
    " * press `command + enter` or `ctrl + enter` to run the cell and exit edit mode.  Running a markdown cell will render it, and running a code cell performs as you expect.\n",
    " * press `shift + enter` to run the cell and travel to the next cell below, possibly inserting a new one.  This is the standard command when you're building the notebook.\n",
    "1. In **Command mode** you have access to your cells in a larger-scale way.  You're in command mode on a cell when the left border of the cell is blue.  You can press `up` or `down` to move between cells, and press `enter` to enter edit mode on the currently selected cells.  You can also cut, copy, paste, and delete cells with appropriate keyboard commands.  Open the *Command Palette* (the keyboard in the top center of the toolbar) to see all the commands you can use in Command mode.\n",
    "\n",
    "## Linearity of code: the kernel\n",
    "\n",
    "A notebook has a **kernel** attached to it.  Think of it as the interactive python interpreter running behind the scenes, executing your commands when you send them.  There are two forms of \"linearity\" (or temporal/time state) going on here, and it can be a bit confusing to new Jupyter users:\n",
    "\n",
    "* **Kernel Linearity**: After you execute a code cell, it gives you its output and places a number next to the top of the cell.  This number is the *order of cell execution* in the kernel.  It's the order the kernel is receiving.  This means you can run cells, tweak them and run them again, run something \"below\" a cell in the notebook, then come back and run the upper cell, *etc.*, and the kernel will keep track of this in terms of the order in which you ran them **chronologically**.  This is the order you want to keep in mind.  It's really useful!  You can start out with a junky-looking notebook, figure out your data analysis, realize you want to change stuff \"in the past\", and just go back and change them.  Once you get used to this, you'll love it.\n",
    "* **Cell Linearity**: There is an obvious visual order to the cells: the top ones \"go first\", and the lower ones \"go next\".  This isn't exactly necessary, though.  It definitely is the goal of the *final product* to go linearly, but programming, and especially data analysis, isn't like reading an essay.  Very often, you'll need to go back and change things, then rerun all the cells that come after the one you just edited.  You may type one line in a cell, hit `shift + enter` to see the output and move on to the next cell, then do that three more times.  You then realize that you'd prefer to have done all that at once, and you can merge those three cells together.  It's a workflow that I hope you'll learn to love.\n",
    "\n",
    "Play around with it now: use an uninitialized variable `my_hat` in a cell, then hit `esc` to leave the cell without running (or hit `shift + enter` to see the error.  Below that, create a cell in which you give the variable a value, then run that cell, followed by the original cell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press `shift+enter` to see an error\n",
    "\n",
    "print(my_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this cell, then re-run the above cell!\n",
    "\n",
    "my_hat = \"Oh, now it works!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll get the hang of it in time.  One other thing to note about jupyter notebooks is that, unlike the python interpretter, you have easy access to your shell (bash, zsh, or cmd, most likely) by using the `!` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!echo \"Hello from a text file!\" > hello.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see the file we just made:\n",
    "\n",
    "# I'm on a windows machine as I create this, so I'll use: \n",
    "!dir \n",
    "\n",
    "# But if you're on a *nix machine (like a MacBook) you should use: \n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python command to open the text file we just made:\n",
    "with open(\"hello.txt\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Again, the windows commands: \n",
    "!del hello.txt\n",
    "\n",
    "# But if you're on a *nix machine you should use: \n",
    "# !rm hello.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because you can access the terminal from jupyter, you can use it to access [pip](https://docs.python.org/3/installing/index.html) to install libraries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this makes a somewhat long printout.  In your final submission of a notebook, you should remove all the long printouts to have a more readable notebook.  Now let's move on to something more interesting.\n",
    "\n",
    "# Visualizing some standard datasets\n",
    "\n",
    "Jupyter notebooks are a great way to work with data.  To describe this, let's load a famous dataset and work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to the diabetes dataset! https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard import statements.  We'll understand these soon enough!\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Jupyter \"magics\": lines beginning with a `%` are how you talk to Jupyter.  Here, I'm telling \n",
    "#   Jupyter to display matplotlib plots as inline, as opposed to the default of having them pop\n",
    "#   up in their own window, buried behind everything else.\n",
    "# Another option is `matplotlib notebook`, which gives the plot a few more features, \n",
    "#   but those features are usually not that necessary unless you're needing to manipulate the \n",
    "#   graphic, like in a 3d plot, or save the individual plot to a .png file.\n",
    "%matplotlib inline\n",
    "\n",
    "# This just makes my plots look nice; it's completely optional\n",
    "plt.style.use(\"fivethirtyeight\") \n",
    "\n",
    "# Now, load the data from scikit-learn, a machine learning library\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# What's in iris?\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "\n",
    "# What is X?\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NumPy](https://docs.scipy.org/doc/numpy/user/quickstart.html) is a linear algebra library written in C & Python.  Basically, you write Python code, but you get the power of C under the hood.  It's the library that all of the PyData stack, all these Python data science libraries, were built off of.  Our dataset `X` is a NumPy array, which is the basic data type in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show four rows\n",
    "X[:4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One staple Python library for working with data is [Pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html), which provides a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) object, which is essentially a NumPy array with lots of extra methods attached to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=iris['feature_names'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape ## a dataset is always arranged as rows = observations, columns = variables/predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is 4-dimensional, so it will be a little bit tricky to visualize.  First, though, we need to add in the _response_ variable, the species of the iris being investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['species'] = iris['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll visualize it by plotting many different 2-dimensional slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['sepal length (cm)'], df['sepal width (cm)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of colors from the elements of the Species column\n",
    "colors = {species: color for species, color in zip(df.species.unique(),['r','g','b'])}\n",
    "color_column = df.species.map(colors)\n",
    "\n",
    "# Create a figure object\n",
    "fig = plt.figure(figsize=(15,12))\n",
    "fig.subplots_adjust(hspace=.5) # This line adds some space between plots\n",
    "\n",
    "# Make all the subplots\n",
    "for i,(x,y) in enumerate(combinations([x for x in df.columns if x != \"species\"],2)):\n",
    "    # x and y are pairs of features.  Scatterplot them!\n",
    "    ax = fig.add_subplot(3,2,i + 1)\n",
    "    ax.scatter(df[x], df[y], c=color_column)\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(y)\n",
    "    plt.title(\"{} vs. {}\".format(y,x));  # The semi-colon is just to make the printout ever-so-slightly nicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a lot.  Let's look at the minimal amount of matplotlib code to generate one of those scatter plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*zip(df.species.unique(),['r','g','b', 'food']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color_column[40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of colors from the elements of the Species column\n",
    "colors = {species: color for species, color in zip(df.species.unique(),['r','g','b'])}\n",
    "color_column = df.species.map(colors)\n",
    "\n",
    "x = \"petal length (cm)\"\n",
    "y = \"petal width (cm)\"\n",
    "plt.scatter(df[x], df[y], c=color_column)\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.title(\"{} vs. {}\".format(y,x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, alternatively, you can use Pandas' built-in matplotlib methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x, y, kind = \"scatter\", c=color_column)\n",
    "plt.title(\"{} vs. {}\".format(y,x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that it's the same plot! That's not a coincidence, pandas just wrote the basic plot code for you.) What about that plot of all the pairs of features?  The library Seaborn contains some helpful plots that can save you a great deal of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few in there on the diagonal, so those are `x` against `x` for each feature `x`.  Those are _histograms_, and they help you to digest a column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we wanted to create Seaborn's color splitting, we'll need to split the data up by class.  \n",
    "# Note the boolean slicing!\n",
    "\n",
    "labels = [0,1,2]\n",
    "pred = \"petal width (cm)\"\n",
    "\n",
    "plt.hist([df[df.species == labels[0]][pred], \n",
    "          df[df.species == labels[1]][pred],\n",
    "          df[df.species == labels[2]][pred]], \n",
    "          stacked=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subplots in Matplotlib \n",
    "\n",
    "To show one more bit about matplotlib, our main plotting library, we'll use another famous dataset: [Anscombe's Quartet](https://en.wikipedia.org/wiki/Anscombe's_quartet). (By the way, double-click on this cell to edit the markdown, and view how links work.  You should definitely use links to format things!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Anscombe's Quartet\n",
    "\n",
    "ansc = pd.DataFrame({'x1':[10.0, 8.0,  13.0,  9.0,  11.0, 14.0, 6.0,  4.0,  12.0,  7.0,  5.0],\n",
    "                     'y1':[8.04, 6.95, 7.58,  8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68],\n",
    "                     'x2':[10.0, 8.0,  13.0,  9.0,  11.0, 14.0, 6.0,  4.0,  12.0,  7.0,  5.0],\n",
    "                     'y2':[9.14, 8.14, 8.74,  8.77, 9.26, 8.10, 6.13, 3.10, 9.13,  7.26, 4.74],\n",
    "                     'x3':[10.0, 8.0,  13.0,  9.0,  11.0, 14.0, 6.0,  4.0,  12.0,  7.0,  5.0],\n",
    "                     'y3':[7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15,  6.42, 5.73],\n",
    "                     'x4':[8.0,  8.0,  8.0,   8.0,  8.0,  8.0,  8.0,  19.0,  8.0,  8.0,  8.0],\n",
    "                     'y4':[6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]})\n",
    "\n",
    "ansc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by checking out the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10,8))\n",
    "axs = [figure.add_subplot(2,2,i) for i in range(1,5)]\n",
    "\n",
    "for i in range(1,5):\n",
    "    axs[i-1].scatter(ansc['x'+str(i)], ansc['y'+str(i)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The incredible thing about Anscombe's quartet is that it's four different datasets, all with the same means, variances, correlation, and linear regression line.  Let's check these facts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Means of the x's:\",\"\",\"\", *[ansc['x{}'.format(i+1)].mean() for i in range(4)], sep='\\t')\n",
    "print(\"Variances of the x's:\",\"\",\"\", *[ansc['x{}'.format(i+1)].var() for i in range(4)], sep='\\t')\n",
    "print(\"Means of the y's:\",\"\",\"\", *[ansc['y{}'.format(i+1)].mean().round(3) for i in range(4)], sep='\\t')\n",
    "print(\"Variances of the y's:\",\"\",\"\", *[ansc['y{}'.format(i+1)].var().round(3) for i in range(4)], sep='\\t')\n",
    "print(\"Correlations between the x's and y's:\",\n",
    "      *[ansc[['x{}'.format(i+1),'y{}'.format(i+1)]].corr().values[0,1].round(3) for i in range(4)], sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That looks a bit messy.  What's going on here is I'm using what's called a [list comprehension](https://docs.python.org/3.6/tutorial/datastructures.html#list-comprehensions), whose basic syntax is:\n",
    "\n",
    "```\n",
    "[<expression> for <item> in <iterable> if <condition>]\n",
    "```\n",
    "\n",
    "and the condition is optional.  For example, from the first code cell up top:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(x) + \" is prime!\"  for x in range(2,30) if is_prime(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This populates a list with `x`s (the expression could be any function of `x`) for each `x` in the given range, provided that `x` is prime.\n",
    "\n",
    "The last thing to note is the _splat operator_, AKA putting a star before a list.  That unpacks a list, and it's best explained by example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Without splat:\", [1,2,3,4,5], sep=\"_SEP_\")\n",
    "print(\"With splat:\", *[1,2,3,4,5], sep=\"_SEP_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we've seen that the data sets have everything in common, except for the fact that their linear regression lines are the same.  To finish, let's compute those and add them to our plots.  Here, we're using [Scikit-Learn](http://scikit-learn.org/stable/), the machine learning library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(4):\n",
    "    # Create the regression model object\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Fit the model to our data.  Note that when you have a one dimensional input, you need to reshape\n",
    "    model.fit(ansc['x'+str(i+1)].values.reshape(-1,1), ansc['y'+str(i+1)])\n",
    "    \n",
    "    models.append(model)\n",
    "    \n",
    "print(\"Slopes of the regression lines:\", \"\", *[round(models[i].coef_[0], 3) for i in range(4)], sep='\\t')\n",
    "print(\"Intercepts of the regression lines:\", *[round(models[i].intercept_) for i in range(4)], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10,8))\n",
    "axs = [figure.add_subplot(2,2,i) for i in range(1,5)]\n",
    "\n",
    "for i in range(1,5):\n",
    "    axs[i-1].scatter(ansc['x'+str(i)].values.reshape(-1,1), ansc['y'+str(i)])\n",
    "    m, b = (models[i-1].coef_[0],models[i-1].intercept_)\n",
    "    axs[i-1].plot([0, 20], [b, m * 20 + b], 'r-', linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a curious dataset!  It was handmade to demonstrate the importance of data visualization."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
